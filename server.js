import express from "express";
import cors from "cors";
import bodyParser from "body-parser";
import { OpenAI } from "openai";

const app = express();
const PORT = process.env.PORT || 3000;

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

app.use(cors());
app.use(bodyParser.json());

app.get("/", (req, res) => {
  res.send("Servidor activo ðŸš€");
});

app.post("/api/chat", async (req, res) => {
  const { mensaje } = req.body;

  // ðŸ›¡ï¸ ValidaciÃ³n estricta para evitar nulls o vacÃ­os
  if (!mensaje || typeof mensaje !== "string" || mensaje.trim() === "") {
    console.error("âŒ Error: mensaje vacÃ­o o invÃ¡lido recibido");
    return res.status(400).json({ error: "Mensaje vacÃ­o o invÃ¡lido." });
  }

  try {
    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "Eres un asistente jurÃ­dico amigable y claro." },
        { role: "user", content: mensaje }
      ]
    });

    const respuesta = response.choices[0]?.message?.content?.trim();

    if (!respuesta) {
      console.error("âš ï¸ OpenAI regresÃ³ una respuesta vacÃ­a");
      return res.status(500).json({ error: "Respuesta vacÃ­a del modelo." });
    }

    res.json({ respuesta });

  } catch (error) {
    console.error("ðŸ”¥ Error al consultar OpenAI:", error);
    res.status(500).json({ error: "Error al consultar ChatGPT" });
  }
});

app.listen(PORT, () => {
  console.log(`âœ… Servidor corriendo en puerto ${PORT}`);
});
